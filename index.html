<!DOCTYPE html>
<html lang="vi">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>WebApp Kh·ª≠ Noise T·∫°p √Çm</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 800px;
      margin: 40px auto;
      padding: 20px;
      background: #f4f4f9;
      color: #333;
    }
    h1 { text-align: center; color: #2c3e50; }
    .container { background: white; padding: 30px; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); }
    input, button { margin: 10px 0; padding: 10px; font-size: 16px; }
    button {
      background: #3498db; color: white; border: none; border-radius: 6px; cursor: pointer; padding: 12px 20px;
    }
    button:hover { background: #2980b9; }
    button:disabled { background: #95a5a6; cursor: not-allowed; }
    audio { width: 100%; margin-top: 20px; }
    .status { margin-top: 15px; font-style: italic; color: #7f8c8d; }
    .progress { width: 100%; height: 8px; background: #ecf0f1; border-radius: 4px; margin: 15px 0; overflow: hidden; }
    .progress-bar { height: 100%; width: 0; background: #27ae60; transition: width 0.3s; }
  </style>
</head>
<body>
  <div class="container">
    <h1>üßπ Kh·ª≠ Noise T·∫°p √Çm</h1>
    <p>Ch·ªçn file √¢m thanh ƒë·ªÉ lo·∫°i b·ªè ti·∫øng ·ªìn n·ªÅn b·∫±ng AI (RNNoise).</p>

    <input type="file" id="audioInput" accept="audio/*" />
    <br/>
    <button id="processBtn" disabled>Kh·ª≠ Noise</button>
    <button id="downloadBtn" style="display:none;">T·∫£i File ƒê√£ X·ª≠ L√Ω</button>

    <div class="progress"><div class="progress-bar" id="progress"></div></div>
    <div class="status" id="status">Ch∆∞a c√≥ file ƒë∆∞·ª£c ch·ªçn.</div>

    <h3>√Çm thanh g·ªëc</h3>
    <audio id="originalAudio" controls></audio>

    <h3>√Çm thanh sau khi kh·ª≠ noise</h3>
    <audio id="denoisedAudio" controls></audio>
  </div>

  <!-- T·∫£i RNNoise WASM -->
  <script src="https://unpkg.com/rnnoise-wasm@0.0.4/dist/rnnoise.js"></script>
  <script>
    let rnnoise = null;
    let originalBlob = null;
    let denoisedBlob = null;

    // Kh·ªüi t·∫°o RNNoise
    async function initRNNoise() {
      if (!rnnoise) {
        document.getElementById("status").textContent = "ƒêang t·∫£i m√¥ h√¨nh RNNoise...";
        rnnoise = await RNNoiseNode.create(new AudioContext());
        document.getElementById("status").textContent = "M√¥ h√¨nh ƒë√£ s·∫µn s√†ng!";
      }
    }

    // X·ª≠ l√Ω khi ch·ªçn file
    document.getElementById("audioInput").addEventListener("change", async (e) => {
      const file = e.target.files[0];
      if (!file) return;

      originalBlob = file;
      const url = URL.createObjectURL(file);

      const originalAudio = document.getElementById("originalAudio");
      originalAudio.src = url;

      document.getElementById("processBtn").disabled = false;
      document.getElementById("status").textContent = `ƒê√£ ch·ªçn: ${file.name}`;
      document.getElementById("downloadBtn").style.display = "none";
      denoisedBlob = null;
    });

    // X·ª≠ l√Ω kh·ª≠ noise
    document.getElementById("processBtn").addEventListener("click", async () => {
      if (!originalBlob) return;

      await initRNNoise();

      const processBtn = document.getElementById("processBtn");
      const status = document.getElementById("status");
      const progress = document.getElementById("progress");

      processBtn.disabled = true;
      status.textContent = "ƒêang x·ª≠ l√Ω...";
      progress.style.width = "0%";

      try {
        // ƒê·ªçc file th√†nh ArrayBuffer
        const arrayBuffer = await originalBlob.arrayBuffer();
        const audioCtx = new AudioContext();
        const audioBuffer = await audioCtx.decodeAudioBuffer(arrayBuffer);

        if (audioBuffer.sampleRate !== 48000) {
          status.textContent = "L·ªói: Ch·ªâ h·ªó tr·ª£ file 48kHz. ƒêang chuy·ªÉn m·∫´u...";
          const offlineCtx = new OfflineAudioContext(1, audioBuffer.duration * 48000, 48000);
          const source = offlineCtx.createBufferSource();
          source.buffer = audioBuffer;
          source.connect(offlineCtx.destination);
          source.start();
          const resampled = await offlineCtx.startRendering();
          audioBuffer = resampled;
        }

        const input = audioBuffer.getChannelData(0);
        const output = new Float32Array(input.length);

        const frameSize = 480; // RNNoise x·ª≠ l√Ω 10ms/frame t·∫°i 48kHz
        let processed = 0;

        for (let i = 0; i < input.length; i += frameSize) {
          const frame = input.subarray(i, i + frameSize);
          if (frame.length < frameSize) break;

          const denoisedFrame = rnnoise.processFrame(frame);
          output.set(denoisedFrame, i);

          processed += frameSize;
          progress.style.width = `${(processed / input.length) * 100}%`;
        }

        // T·∫°o AudioBuffer m·ªõi
        const denoisedBuffer = audioCtx.createBuffer(1, output.length, 48000);
        denoisedBuffer.copyToChannel(output, 0);

        // Xu·∫•t th√†nh Blob WAV
        denoisedBlob = bufferToWave(denoisedBuffer);

        const url = URL.createObjectURL(denoisedBlob);
        document.getElementById("denoisedAudio").src = url;
        document.getElementById("downloadBtn").style.display = "inline-block";

        status.textContent = "Ho√†n t·∫•t! ƒê√£ kh·ª≠ noise th√†nh c√¥ng.";
      } catch (err) {
        console.error(err);
        status.textContent = "L·ªói: " + err.message;
      } finally {
        processBtn.disabled = false;
      }
    });

    // T·∫£i xu·ªëng
    document.getElementById("downloadBtn").addEventListener("click", () => {
      if (!denoisedBlob) return;
      const url = URL.createObjectURL(denoisedBlob);
      const a = document.createElement("a");
      a.href = url;
      a.download = "denoised_audio.wav";
      a.click();
    });

    // H√†m chuy·ªÉn AudioBuffer sang WAV Blob
    function bufferToWave(abuffer) {
      const numChannels = abuffer.numberOfChannels;
      const sampleRate = abuffer.sampleRate;
      const format = 3; // PCM float32
      const bitDepth = 32;

      let result;
      if (numChannels === 2) {
        result = interleave(abuffer.getChannelData(0), abuffer.getChannelData(1));
      } else {
        result = abuffer.getChannelData(0);
      }

      const buffer = new ArrayBuffer(44 + result.length * 4);
      const view = new DataView(buffer);

      // RIFF header
      writeString(view, 0, 'RIFF');
      view.setUint32(4, 36 + result.length * 4, true);
      writeString(view, 8, 'WAVE');
      // FMT sub-chunk
      writeString(view, 12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, format, true); // float
      view.setUint16(22, numChannels, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * numChannels * bitDepth/8, true);
      view.setUint16(32, numChannels * bitDepth/8, true);
      view.setUint16(34, bitDepth, true);
      // Data sub-chunk
      writeString(view, 36, 'data');
      view.setUint32(40, result.length * 4, true);

      floatTo16BitPCM(view, 44, result);

      return new Blob([buffer], { type: 'audio/wav' });
    }

    function interleave(inputL, inputR) {
      const result = new Float32Array(inputL.length + inputR.length);
      for (let i = 0; i < inputL.length; ++i) {
        result[i * 2] = inputL[i];
        result[i * 2 + 1] = inputR[i];
      }
      return result;
    }

    function floatTo16BitPCM(output, offset, input) {
      for (let i = 0; i < input.length; i++, offset += 4) {
        const s = Math.max(-1, Math.min(1, input[i]));
        output.setFloat32(offset, s, true);
      }
    }

    function writeString(view, offset, string) {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }
  </script>
</body>
</html>
